{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classifying cifar10 dataset using feedforward neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to datasets/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf68d7738409438c840adb602e9df676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets/cifar-10-python.tar.gz to datasets/\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='datasets/',download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2236e1fae10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43) #42 is answer to life universe and everything and seed should be prime so +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,valid_dataset = random_split(dataset,[45000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CIFAR10(root='datasets/',train=False,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for GPU optims\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking=True) #I don't fully understand this non_blocking term, just saw it somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader(): #wrapper over DataLoader class, to push it to device and create __iter__ class for taking full advantage of GPU\n",
    "    def __init__(self,data_loader,device):\n",
    "        self.data_loader = data_loader\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self): #this class makes the magic of GPU happen\n",
    "        for batch in self.data_loader:\n",
    "            yield(to_device(batch,self.device))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loaders\n",
    "batch_size=128\n",
    "train_loader = DeviceDataLoader(DataLoader(train_dataset,batch_size,shuffle=True,pin_memory=True,num_workers=4),device)\n",
    "valid_loader = DeviceDataLoader(DataLoader(train_dataset,batch_size*2,pin_memory=True,num_workers=4),device)\n",
    "test_loader  = DeviceDataLoader(DataLoader(train_dataset,batch_size*2,pin_memory=True,num_workers=4),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class \n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self,in_size,num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_size,16)\n",
    "        self.linear2 = nn.Linear(16,32)\n",
    "        self.linear3 = nn.Linear(32,num_classes)\n",
    "    \n",
    "    def forward(self,X_batch):\n",
    "        out = X_batch.view(X_batch.size(0),-1)\n",
    "        out = self.linear1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def valid_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        _,preds = torch.max(out,dim=1)\n",
    "        acc = torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
    "        return {'loss':loss,'acc':acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loader):\n",
    "    out = [model.valid_step(batch) for batch in loader]\n",
    "    batch_loss = [x['loss'] for x in out]\n",
    "    batch_acc  = [x['acc'] for x in out]\n",
    "    epoch_loss = torch.stack(batch_loss).mean()\n",
    "    epoch_acc  = torch.stack(batch_acc).mean()\n",
    "    print(f\"loss is {epoch_loss} and acc is {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,valid_loader,num_epochs=10,lr=0.01,optim_func=torch.optim.SGD):\n",
    "    optim = optim_func(model.parameters(),lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.train_step(batch)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Model(3*32*32,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.3169798851013184 and acc is 0.1039692834019661\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.1425089836120605 and acc is 0.17021217942237854\n",
      "loss is 1.991416335105896 and acc is 0.258444607257843\n",
      "loss is 1.966501235961914 and acc is 0.27538618445396423\n",
      "loss is 1.9150358438491821 and acc is 0.3040003478527069\n",
      "loss is 1.8939666748046875 and acc is 0.31960582733154297\n",
      "loss is 1.8701751232147217 and acc is 0.3294282555580139\n",
      "loss is 1.8553366661071777 and acc is 0.33513760566711426\n",
      "loss is 1.8219321966171265 and acc is 0.34993162751197815\n",
      "loss is 1.8105708360671997 and acc is 0.3525923490524292\n",
      "loss is 1.800219178199768 and acc is 0.35188475251197815\n",
      "loss is 1.7753745317459106 and acc is 0.3679882884025574\n",
      "loss is 1.760054349899292 and acc is 0.3707972466945648\n",
      "loss is 1.75911545753479 and acc is 0.36866655945777893\n",
      "loss is 1.7283658981323242 and acc is 0.3862091302871704\n",
      "loss is 1.73177969455719 and acc is 0.3816849887371063\n",
      "loss is 1.7058794498443604 and acc is 0.39375531673431396\n",
      "loss is 1.6966466903686523 and acc is 0.3955557644367218\n",
      "loss is 1.7286349534988403 and acc is 0.3858824670314789\n",
      "loss is 1.7083643674850464 and acc is 0.39197972416877747\n",
      "loss is 1.6818403005599976 and acc is 0.4028480350971222\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,20,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.697308897972107 and acc is 0.4004066288471222\n",
      "loss is 1.6716159582138062 and acc is 0.405342698097229\n",
      "loss is 1.6825312376022339 and acc is 0.39685899019241333\n",
      "loss is 1.6554441452026367 and acc is 0.4097975790500641\n",
      "loss is 1.7212398052215576 and acc is 0.3892178535461426\n",
      "loss is 1.663379430770874 and acc is 0.40922051668167114\n",
      "loss is 1.6307307481765747 and acc is 0.4199378788471222\n",
      "loss is 1.629482626914978 and acc is 0.4206126034259796\n",
      "loss is 1.632980227470398 and acc is 0.41924893856048584\n",
      "loss is 1.6295881271362305 and acc is 0.41804152727127075\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,10,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.5931857824325562 and acc is 0.43644973635673523\n",
      "loss is 1.5921663045883179 and acc is 0.4371280372142792\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,2,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.5921789407730103 and acc is 0.4377654790878296\n",
      "loss is 1.590474247932434 and acc is 0.43742629885673523\n",
      "loss is 1.5900518894195557 and acc is 0.43892577290534973\n",
      "loss is 1.589621901512146 and acc is 0.4382093548774719\n",
      "loss is 1.588780164718628 and acc is 0.43806639313697815\n",
      "loss is 1.5883747339248657 and acc is 0.4387455880641937\n",
      "loss is 1.5880250930786133 and acc is 0.4377468228340149\n",
      "loss is 1.5870319604873657 and acc is 0.43868163228034973\n",
      "loss is 1.5874300003051758 and acc is 0.43840286135673523\n",
      "loss is 1.587885856628418 and acc is 0.4376482665538788\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,10,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
