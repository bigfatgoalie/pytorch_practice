{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classifying cifar10 dataset using feedforward neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='datasets/',download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a4b6c100b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43) #42 is answer to life universe and everything and seed should be prime so +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,valid_dataset = random_split(dataset,[45000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CIFAR10(root='datasets/',train=False,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for GPU optims\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking=True) #I don't fully understand this non_blocking term, just saw it somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader(): #wrapper over DataLoader class, to push it to device and create __iter__ class for taking full advantage of GPU\n",
    "    def __init__(self,data_loader,device):\n",
    "        self.data_loader = data_loader\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self): #this class makes the magic of GPU happen\n",
    "        for batch in self.data_loader:\n",
    "            yield(to_device(batch,self.device))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loaders\n",
    "batch_size=128\n",
    "train_loader = DeviceDataLoader(DataLoader(train_dataset,batch_size,shuffle=True,pin_memory=True,num_workers=4),device)\n",
    "valid_loader = DeviceDataLoader(DataLoader(valid_dataset,batch_size*2,pin_memory=True,num_workers=4),device)\n",
    "test_loader  = DeviceDataLoader(DataLoader(test_dataset,batch_size*2,pin_memory=True,num_workers=4),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class \n",
    "class CIFAR10Model(nn.Module):\n",
    "    def __init__(self,in_size,num_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_size,16)\n",
    "        self.linear2 = nn.Linear(16,32)\n",
    "        self.linear3 = nn.Linear(32,num_classes)\n",
    "    \n",
    "    def forward(self,X_batch):\n",
    "        out = X_batch.view(X_batch.size(0),-1)\n",
    "        out = self.linear1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def valid_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        _,preds = torch.max(out,dim=1)\n",
    "        acc = torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
    "        return {'loss':loss,'acc':acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,loader):\n",
    "    out = [model.valid_step(batch) for batch in loader]\n",
    "    batch_loss = [x['loss'] for x in out]\n",
    "    batch_acc  = [x['acc'] for x in out]\n",
    "    epoch_loss = torch.stack(batch_loss).mean()\n",
    "    epoch_acc  = torch.stack(batch_acc).mean()\n",
    "    print(f\"loss is {epoch_loss} and acc is {epoch_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,valid_loader,num_epochs=10,lr=0.01,optim_func=torch.optim.SGD):\n",
    "    optim = optim_func(model.parameters(),lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.train_step(batch)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Model(3*32*32,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.3160152435302734 and acc is 0.09967830777168274\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.107146739959717 and acc is 0.24040670692920685\n",
      "loss is 1.9849262237548828 and acc is 0.2876838147640228\n",
      "loss is 1.9257242679595947 and acc is 0.31324678659439087\n",
      "loss is 1.8856319189071655 and acc is 0.32784926891326904\n",
      "loss is 1.8572403192520142 and acc is 0.3390280306339264\n",
      "loss is 1.8348076343536377 and acc is 0.35360753536224365\n",
      "loss is 1.8226183652877808 and acc is 0.3413258194923401\n",
      "loss is 1.8284438848495483 and acc is 0.35458409786224365\n",
      "loss is 1.8101924657821655 and acc is 0.3517233431339264\n",
      "loss is 1.8142696619033813 and acc is 0.36432674527168274\n",
      "loss is 1.7652397155761719 and acc is 0.3789292275905609\n",
      "loss is 1.7552082538604736 and acc is 0.3802504539489746\n",
      "loss is 1.7549991607666016 and acc is 0.37775737047195435\n",
      "loss is 1.7340844869613647 and acc is 0.38105469942092896\n",
      "loss is 1.7693204879760742 and acc is 0.38003215193748474\n",
      "loss is 1.7201160192489624 and acc is 0.38823527097702026\n",
      "loss is 1.712712287902832 and acc is 0.38908547163009644\n",
      "loss is 1.7282593250274658 and acc is 0.38420265913009644\n",
      "loss is 1.7019939422607422 and acc is 0.3926011025905609\n",
      "loss is 1.6963655948638916 and acc is 0.3978515565395355\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,20,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.8975578546524048 and acc is 0.3483111262321472\n",
      "loss is 1.9039634466171265 and acc is 0.3117302358150482\n",
      "loss is 1.719519853591919 and acc is 0.38485753536224365\n",
      "loss is 1.74394953250885 and acc is 0.38650044798851013\n",
      "loss is 1.7966158390045166 and acc is 0.365234375\n",
      "loss is 1.6935116052627563 and acc is 0.3919462263584137\n",
      "loss is 1.6756168603897095 and acc is 0.40275734663009644\n",
      "loss is 1.8368644714355469 and acc is 0.37218520045280457\n",
      "loss is 1.6405953168869019 and acc is 0.41362589597702026\n",
      "loss is 1.646091103553772 and acc is 0.4157743453979492\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,10,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.581303596496582 and acc is 0.4378446638584137\n",
      "loss is 1.5832111835479736 and acc is 0.43869486451148987\n",
      "loss is 1.5853254795074463 and acc is 0.43869486451148987\n",
      "loss is 1.5784053802490234 and acc is 0.4415096342563629\n",
      "loss is 1.5766887664794922 and acc is 0.4451746344566345\n",
      "loss is 1.5776891708374023 and acc is 0.43872934579849243\n",
      "loss is 1.5743999481201172 and acc is 0.4405330717563629\n",
      "loss is 1.5794543027877808 and acc is 0.43970590829849243\n",
      "loss is 1.573434829711914 and acc is 0.44554227590560913\n",
      "loss is 1.570276141166687 and acc is 0.4469553828239441\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,10,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.5779670476913452 and acc is 0.4387982487678528\n",
      "loss is 1.5762842893600464 and acc is 0.4502527713775635\n",
      "loss is 1.5722335577011108 and acc is 0.4482996463775635\n",
      "loss is 1.5735406875610352 and acc is 0.443439781665802\n",
      "loss is 1.5682989358901978 and acc is 0.4507697522640228\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,5,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.5682989358901978 and acc is 0.4507697522640228\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.523135781288147 and acc is 0.45634764432907104\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 1.4788137674331665 and acc is 0.47467100620269775\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
