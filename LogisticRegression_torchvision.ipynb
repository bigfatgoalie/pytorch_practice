{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first import torch, torchvision and the MNIST dataset loader\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3fe6b1c9e24142a18c35cf0190fed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e10c04af44d72a038bbe8d99bcf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d2df5df7c34f8c8bea57ecc863263a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8237eba794e2bb0b6611905d974d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to mnist/MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(root='mnist/',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.pt', 'training.pt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('mnist/MNIST/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the dataset already has 2 splits into test and train\n",
    "#by default when MNIST dataset constructor is called it picks only train set, the test set can be imported by specifying train=False\n",
    "train_dataset = MNIST(root='mnist/')\n",
    "test_dataset  = MNIST(root='mnist/',train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so 60k train and 10k test images\n",
    "#to see what image looks like we need to plot via matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,label = train_dataset[10]\n",
    "plt.imshow(image,cmap='Greys')\n",
    "print(f\"The digit is {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the images are not HD, as they are of size 28*28, the number 3 is not even clear to me\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now dataset imported is not in form of tensors\n",
    "#we can convert manually, or just use transforms.ToTensor in the dataset constructor\n",
    "train_dataset = MNIST(root='mnist/',train=True,transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root='mnist/',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have train and test splits but a validation set is also needed, so I'll split the train set into 2 parts\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = random_split(train_dataset,[50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have the dataset in form of tensors, next step: create the dataLoader to load data in batches\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size,shuffle=True)\n",
    "valid_loader = DataLoader(valid_data,batch_size) #no shuffle required as only used to measure model performance\n",
    "test_loader = DataLoader(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to create model, it is better to define all related functions in a model class\n",
    "#inherit your model class from torch.nn.Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    #constructor method\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,num_classes)\n",
    "        \n",
    "    def forward(self,X_batch):\n",
    "        X_batch = X_batch.reshape(-1,784)\n",
    "        out = self.linear(X_batch)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def valid_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        acc = accuracy(out,labels)\n",
    "        return {'valid_loss':loss.detach(), 'valid_accuracy':acc.detach()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,valid_loader):\n",
    "    outputs = [model.valid_step(batch) for batch in valid_loader]\n",
    "    batch_losses = [x['valid_loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean() \n",
    "    batch_accs = [x['valid_accuracy'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()\n",
    "    print(f\"'valid_loss': {epoch_loss.item()}, 'valid_accuracy': {epoch_acc.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'valid_loss': 2.3306705951690674, 'valid_accuracy': 0.07565268874168396\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0145,  0.0247, -0.0111,  ...,  0.0129, -0.0287, -0.0001],\n",
       "         [ 0.0219, -0.0177,  0.0104,  ...,  0.0013, -0.0218, -0.0232],\n",
       "         [ 0.0202, -0.0147, -0.0078,  ..., -0.0213, -0.0089,  0.0257],\n",
       "         ...,\n",
       "         [ 0.0310,  0.0332,  0.0116,  ...,  0.0299, -0.0062,  0.0087],\n",
       "         [ 0.0020,  0.0101, -0.0265,  ..., -0.0284,  0.0088,  0.0258],\n",
       "         [-0.0149, -0.0281,  0.0085,  ...,  0.0348, -0.0066,  0.0231]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0261,  0.0011, -0.0185,  0.0273, -0.0208,  0.0055, -0.0286,  0.0100,\n",
       "         -0.0008, -0.0044], requires_grad=True)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,valid_loader,num_epochs=10,lr=0.001,optim_func=torch.optim.SGD):\n",
    "    optim = optim_func(model.parameters(),lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.train_step(batch)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        res = evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'valid_loss': 1.9616447687149048, 'valid_accuracy': 0.584750771522522\n",
      "'valid_loss': 1.6902490854263306, 'valid_accuracy': 0.7204311490058899\n",
      "'valid_loss': 1.487326979637146, 'valid_accuracy': 0.7632516026496887\n",
      "'valid_loss': 1.3340649604797363, 'valid_accuracy': 0.785897970199585\n",
      "'valid_loss': 1.2161204814910889, 'valid_accuracy': 0.8014240264892578\n",
      "'valid_loss': 1.1235768795013428, 'valid_accuracy': 0.8137856125831604\n",
      "'valid_loss': 1.0494580268859863, 'valid_accuracy': 0.8180379867553711\n",
      "'valid_loss': 0.9887734055519104, 'valid_accuracy': 0.8221914768218994\n",
      "'valid_loss': 0.9383103847503662, 'valid_accuracy': 0.8280261158943176\n",
      "'valid_loss': 0.8957948088645935, 'valid_accuracy': 0.832179605960846\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'valid_loss': 0.8676035404205322, 'valid_accuracy': 0.8404865264892578\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so model trained successfully\n",
    "#to test on 1 single image\n",
    "image,label =  test_dataset[7777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0],cmap='Greys')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.unsqueeze(0)\n",
    "pred_prob = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3729, -1.1022,  0.7118,  1.4188, -2.9178,  1.6937,  1.2008, -1.5527,\n",
       "          0.9985, -2.1058]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.6937], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([5]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(pred_prob,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so predicted label is 5 and the original is also 5, therefore model training successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
