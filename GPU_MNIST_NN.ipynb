{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performance on mnist with linear model doesn't go beyond 87%, so now we'll try with simple feed-forward neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='datasets/mnist/',transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: datasets/mnist/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so default split is train data and has 60k samples, we will create a smaller 10k sample validation dataset\n",
    "train_ds,valid_ds = random_split(dataset,[50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data loaders to load data in batches\n",
    "#now for GPU optimization, pin_memory is used for faster loading, but won't be much different in MNIST case\n",
    "train_loader = DataLoader(train_ds,batch_size,shuffle=True,pin_memory=True,num_workers=2)\n",
    "valid_loader = DataLoader(valid_ds,batch_size*2,num_workers=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#now images will be of shape 28*28 which is equal to 784<br>\n",
    "#therefore input layer size will be 784<br>\n",
    "#this is just one extra matrix multiplication than the linear model<br>\n",
    "#if linear was y1 = w1*x+b1 now we have y2 = w2*y1+b<br>\n",
    "#we go from 784 to 32 then from 32 to 10 which is the number of output classes(0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creation\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,out_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size,hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size,out_size)\n",
    "    \n",
    "    def forward(self,X_batch):\n",
    "        X_batch = X_batch.view(X_batch.size(0),-1) #Flatten the image tensors from 28*28 to 784\n",
    "        out = self.linear1(X_batch)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "    def train_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def valid_step(self,X_batch):\n",
    "        images,labels = X_batch\n",
    "        out = self.forward(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        _,preds = torch.max(out,dim=1)\n",
    "        acc = torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
    "        return {\"loss\":loss,\"acc\":acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel(784,32,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    else:\n",
    "        return data.to(device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now data loader has to put data on the cuda device\n",
    "#for this we need a __iter__ and __len__ method to retrieve a batch and number of batches\n",
    "class DeviceDataLoader():\n",
    "    #Wrap dataloader to move data to device\n",
    "    def __init__(self,dl,device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield to_device(batch,self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader,device)\n",
    "valid_loader = DeviceDataLoader(valid_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,valid_loader):\n",
    "    outputs = [model.valid_step(batch) for batch in valid_loader]\n",
    "    batch_losses = [x['loss'] for x in outputs]\n",
    "    loss = torch.stack(batch_losses).mean()\n",
    "    batch_accs = [x['acc'] for x in outputs]\n",
    "    acc = torch.stack(batch_accs).mean()\n",
    "    print(f\"loss is {loss} and acc is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MnistModel(784,32,10)\n",
    "to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,valid_loader,epochs=20,lr=0.01,optim_func=torch.optim.SGD):\n",
    "    optim = optim_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            loss = model.train_step(batch)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        res = evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 2.3045036792755127 and acc is 0.10488281399011612\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.3634752333164215 and acc is 0.8985351324081421\n",
      "loss is 0.30991020798683167 and acc is 0.911914050579071\n",
      "loss is 0.27482175827026367 and acc is 0.919238269329071\n",
      "loss is 0.24124775826931 and acc is 0.9287109375\n",
      "loss is 0.2216728776693344 and acc is 0.9351562261581421\n",
      "loss is 0.20776580274105072 and acc is 0.94287109375\n",
      "loss is 0.19890932738780975 and acc is 0.9447265863418579\n",
      "loss is 0.18860359489917755 and acc is 0.94775390625\n",
      "loss is 0.1803520768880844 and acc is 0.949414074420929\n",
      "loss is 0.17987488210201263 and acc is 0.946484386920929\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.16593708097934723 and acc is 0.954296886920929\n",
      "loss is 0.16016976535320282 and acc is 0.955859363079071\n",
      "loss is 0.15378592908382416 and acc is 0.956835925579071\n",
      "loss is 0.15331526100635529 and acc is 0.956835925579071\n",
      "loss is 0.15337739884853363 and acc is 0.9571288824081421\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,valid_loader,5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got 95% now with a simple double linear regression, although the relu layer makes it a neural net\n",
    "test_dataset = MNIST(root='datasets/mnist/',train=False,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_dataset,batch_size=256),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.12460916489362717 and acc is 0.962695300579071\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now try same model with Fashion MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
