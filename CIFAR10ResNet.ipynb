{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CIFAR10ResNet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR62zlRSVnf0"
      },
      "source": [
        "#import everything\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSMMWX1lVnf6"
      },
      "source": [
        "#what to do differently\n",
        "1. Use test set as validation set,=\n",
        "2. Normalise data channel-wise, so mean of values is 0 and deviation 1\n",
        "3. Apply different transformations on the data for data augmentation`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nVwJmHiVnf6"
      },
      "source": [
        "import torchvision.transforms as tt"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeuJ4OyjVnf6"
      },
      "source": [
        "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) #mean for each channel, followed by s.deviations\n",
        "#normalised as (value-mean)/deviation\n",
        "train_transforms = tt.Compose([tt.RandomCrop(32,padding=4,padding_mode='reflect'),\n",
        "                               tt.RandomHorizontalFlip(),\n",
        "                               tt.ToTensor(),\n",
        "                               tt.Normalize(*stats,inplace=True)])\n",
        "validation_transforms = tt.Compose([tt.ToTensor(),tt.Normalize(*stats)])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSJAqICMVnf7",
        "outputId": "738c13fd-de2e-4423-d361-9688ac490160"
      },
      "source": [
        "train_dataset = CIFAR10(root='datasets/',download=True,transform=train_transforms)\n",
        "valid_dataset = CIFAR10(root='datasets/',train=False,transform=validation_transforms)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruNCEheGVnf7",
        "outputId": "4dae9441-9aaa-4322-8d7c-c8ade034272d"
      },
      "source": [
        "train_dataset.classes"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S206RJdSVnf8"
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data,device):\n",
        "    if isinstance(data,(list,tuple)):\n",
        "        return [to_device(x,device) for x in data]\n",
        "    return data.to(device,non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader(): #wrapper over DataLoader class, to push it to device and create __iter__ class for taking full advantage of GPU\n",
        "    def __init__(self,data_loader,device):\n",
        "        self.data_loader = data_loader\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self): #this class makes the magic of GPU happen\n",
        "        for batch in self.data_loader:\n",
        "            yield(to_device(batch,self.device))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_loader)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZXBqvRBVnf8",
        "outputId": "6bb3356b-1438-4a4e-fb38-62bfdde56f44"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of---Zr8Vnf8"
      },
      "source": [
        "batch_size = 400\n",
        "train_loader = DeviceDataLoader(DataLoader(train_dataset,batch_size,shuffle=True,num_workers=0,pin_memory=True),device)\n",
        "valid_loader = DeviceDataLoader(DataLoader(valid_dataset,batch_size*2,num_workers=0,pin_memory=True),device)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZL4w63-Vnf8"
      },
      "source": [
        "New thing now is addition of a Residual Block which adds the original input back to the output feature map\n",
        "<br>so f(x) is changed to f(x) + x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LlExQPyVnf9"
      },
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,3,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(3,3,kernel_size=3,stride=1,padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        #notice that neither the size of image nor the number of channels change here\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(x)\n",
        "        out = self.conv2(x)\n",
        "        return self.relu2(x) + x #relu can be applied before or after adding input"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkEEE4DkVnf9"
      },
      "source": [
        "simple_resnet = to_device(SimpleResidualBlock(),device)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E41nr7mZVnf9",
        "outputId": "f6b8357f-e4f8-41b2-d928-e6419f5a8dee"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    out = simple_resnet(images)\n",
        "    print(out.shape)\n",
        "    break"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([400, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k04s-dY0Vnf9"
      },
      "source": [
        "del simple_resnet, images, labels\n",
        "torch.cuda.empty_cache()\n",
        "#free gpu memory"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXCYJbjlVnf9"
      },
      "source": [
        "This small change makes a huge improvement in the model\n",
        "<br>Also, after each conv layer, we add a batch norm layer\n",
        "<br> Learn more about the architecture here https://myrtle.ai/learn/how-to-train-your-resnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVu_vYv3Vnf-"
      },
      "source": [
        "class ImageBase(nn.Module):\n",
        "    def train_step(self,X_batch):\n",
        "        images,labels = X_batch\n",
        "        out = self.forward(images)\n",
        "        loss = F.cross_entropy(out,labels)\n",
        "        return loss\n",
        "    \n",
        "    def valid_step(self,X_batch):\n",
        "        images,labels = X_batch\n",
        "        out = self.forward(images)\n",
        "        loss = F.cross_entropy(out,labels)\n",
        "        _,preds = torch.max(out,dim=1)\n",
        "        acc = torch.tensor(torch.sum(preds==labels).item()/len(preds))\n",
        "        return {'loss':loss,'acc':acc}"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHf_mxXgVnf-"
      },
      "source": [
        "def conv_block(in_channels,out_channels,pool=False):\n",
        "    layers = [nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=1,padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool:\n",
        "        layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ankNrseDVnf-"
      },
      "source": [
        "class ResNet9(ImageBase):\n",
        "    def __init__(self,in_channels,num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_block(in_channels,64)\n",
        "        self.conv2 = conv_block(64,128,pool=True)\n",
        "        self.res1  = nn.Sequential(conv_block(128,128),conv_block(128,128))\n",
        "        \n",
        "        self.conv3 = conv_block(128,256,pool=True)\n",
        "        self.conv4 = conv_block(256,512,pool=True)\n",
        "        self.res2  = nn.Sequential(conv_block(512,512),conv_block(512,512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512,num_classes))\n",
        "    def forward(self,X_batch):\n",
        "        out = self.conv1(X_batch)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        return self.classifier(out)       "
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4QvWx3QVnf_"
      },
      "source": [
        "model = to_device(ResNet9(3,10),device)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eocj5WfeVnf_",
        "outputId": "f31a705d-c61b-4069-d5ab-1cafb5dca884"
      },
      "source": [
        "model"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet9(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res1): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res2): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2TbORCUVnf_"
      },
      "source": [
        "Now train process also a little different\n",
        "<br>1. learning rate changed after every batch, instead of using a fixed one every batch. Here increase it for initial 30% of epochs and then gradually decrease to very low value for the rest.\n",
        "<br>2. Weight decay regularization\n",
        "<br>3. Gradient Clipping of large gradient values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g5ocUNMVnf_"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model,loader):\n",
        "    model.eval()\n",
        "    out = [model.valid_step(batch) for batch in loader]\n",
        "    batch_loss = [x['loss'] for x in out]\n",
        "    batch_acc  = [x['acc'] for x in out]\n",
        "    epoch_loss = torch.stack(batch_loss).mean()\n",
        "    epoch_acc  = torch.stack(batch_acc).mean()\n",
        "    print(f\"loss is {epoch_loss} and acc is {epoch_acc}\")\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs,max_lr,model,train_loader,valid_loader,weight_decay=0,grad_clip=None,optim_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    optimizer = optim_func(model.parameters(),max_lr,weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs,steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            loss = model.train_step(batch)\n",
        "            loss.backward()\n",
        "            \n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(),grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "            \n",
        "        evaluate(model,valid_loader)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhTM8XZBVngA",
        "outputId": "9cd6ac88-0bbc-4bd7-e61f-eaf76e1db4bf"
      },
      "source": [
        "evaluate(model,valid_loader)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is 2.308152675628662 and acc is 0.10673077404499054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtXy0kaVngA"
      },
      "source": [
        "epochs = 8\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "optim_func = torch.optim.Adam"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXWi2UQKVngA",
        "outputId": "9f2d6eee-15b5-4111-d386-65732662c355"
      },
      "source": [
        "fit_one_cycle(epochs,max_lr,model,train_loader,valid_loader,weight_decay,grad_clip,optim_func)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is 1.2002620697021484 and acc is 0.5823076963424683\n",
            "loss is 1.417062759399414 and acc is 0.5799999833106995\n",
            "loss is 0.7173216342926025 and acc is 0.7549999952316284\n",
            "loss is 0.6920413970947266 and acc is 0.7737500667572021\n",
            "loss is 0.5628334283828735 and acc is 0.8066346049308777\n",
            "loss is 0.4335850477218628 and acc is 0.8489423990249634\n",
            "loss is 0.315218985080719 and acc is 0.8934614658355713\n",
            "loss is 0.2876301407814026 and acc is 0.9033653736114502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yiqEIt4VngB",
        "outputId": "ee39fa16-7790-4493-923e-3d57c6530be1"
      },
      "source": [
        "fit_one_cycle(5,0.001,model,train_loader,valid_loader,weight_decay,grad_clip,optim_func)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss is 0.3243520259857178 and acc is 0.8898076415061951\n",
            "loss is 0.4771917164325714 and acc is 0.8474999666213989\n",
            "loss is 0.34957972168922424 and acc is 0.8843269348144531\n",
            "loss is 0.28438901901245117 and acc is 0.9109615683555603\n",
            "loss is 0.26964375376701355 and acc is 0.914711594581604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLyqqwS_XKG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}